{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "from babel_ai.analyzer import SimilarityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test behavior of Perplexity Measure\n",
    "\n",
    "This notebook should provide us with a test bed for our new perplexity measure.\n",
    "- the Perplexity Measure captures whether or not a new text in and of itself is sensible, if within one text, we only have a random token sequence, if we have unlikely continuation throughout the text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SimilarityAnalyzer(\n",
    "    analyze_window=1, # we only look at current and last text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample texts\n",
    "\n",
    "In order to test our analytical tools, we need some carefully crafted text snippets, to make predictions about which of the measures should react how to our texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_symbols_1 = \"\".join(random.choices(string.ascii_letters + string.digits, k=100))\n",
    "random_symbols_2 = \"\".join(random.choices(string.ascii_letters + string.digits, k=100))\n",
    "\n",
    "random_keystrokes_1 = \"oaesdrutoa Ã¥egfu n  ona!)(#tr khoaer ket gl[6().0654 oegf untlgfoaug ngf rtoufglruef \"\n",
    "random_keystrokes_2 = \"ttrog-n gfy@-nrt gfln 1rtn g3!!fgf   f5244564%' gfuoaert ngfuoa rtn r n reaortegf0.!!\"\n",
    "\n",
    "de_klettern_1 = \"Das Klettern an den Felsen der deutschen Mittelgebirge hat eine lange Tradition.\"\n",
    "de_klettern_2 = \"Seit der Trend ab den 1970er Jahren so richtig Fahrt aufgenommen hat, treten immer wieder Konflikte auf.\"\n",
    "\n",
    "en_klettern_1 = \"Climbing the rocks of the German midlands has a long tradition.\"\n",
    "en_klettern_2 = \"Since the trend started in the 1970s, there are always conflicts.\"\n",
    "\n",
    "en_receipe_1 = \"First make the chutney. Put the coriander, garlic, nuts, caster sugar and lemon juice in a blender.\"\n",
    "en_receipe_2 = \"Add half the chopped chillies, season generously, then blitz smooth2 if need be, add a tablspoon of water.\"\n",
    "\n",
    "en_unlikely_1 = \"The velutinous nullifidian absquatulated whilst borborygmic.\"\n",
    "en_unlikely_2 = \"Her zabernism caused much widdershins smellfungus amongst xenodochial folk.\"\n",
    "\n",
    "# Expert text with highly specialized vocabulary\n",
    "# Should be grammatically correct but use very domain-specific terms\n",
    "en_expert_1 = \"The myocardial sarcomeres exhibit actin-myosin cross-bridge cycling during systole.\"\n",
    "en_expert_2 = \"Phosphorylation of troponin-I via beta-adrenergic stimulation enhances contractility.\"\n",
    "\n",
    "# Nonsense text with high perplexity\n",
    "en_nonsense_1 = \"The colorful ideas sleep furiously while time drinks mountains.\"\n",
    "en_nonsense_2 = \"Gentle clouds taste the walking dreams of silent laughter.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing perplexity\n",
    "Now we test, whether our tests produce the results, we believe they should produce. We start analyzing, if our predictions for the perplexity measures hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random symbols\n",
    "# Prediction: Bayesian Surprise should be low, Perplexity should be high.\n",
    "print(\"\\nPrediction: Perplexity should be high.\")\n",
    "random_symbols_result = analyzer.analyze(\n",
    "    [random_symbols_1, random_symbols_2]\n",
    ")\n",
    "print(\"Perplexity for random symbols: \", random_symbols_result.token_perplexity)\n",
    "\n",
    "# Random keystrokes\n",
    "# Prediction: Bayesian Surprise should be low, Perplexity should be high.\n",
    "print(\"\\nPrediction: Perplexity should be high.\")\n",
    "random_keystrokes_result = analyzer.analyze(\n",
    "    [random_keystrokes_1, random_keystrokes_2]\n",
    ")\n",
    "print(\"Perplexity for random keystrokes: \", random_keystrokes_result.token_perplexity)\n",
    "\n",
    "# German climbing\n",
    "# Prediction: Perplexity should be low.\n",
    "print(\"\\nPrediction: Perplexity should be low.\")\n",
    "de_klettern_result = analyzer.analyze(\n",
    "    [de_klettern_1, de_klettern_2]\n",
    ")\n",
    "print(\"Perplexity for German climbing: \", de_klettern_result.token_perplexity)\n",
    "\n",
    "# English climbing\n",
    "# Prediction: Perplexity should be low.\n",
    "print(\"\\nPrediction: Perplexity should be low.\")\n",
    "en_klettern_result = analyzer.analyze(\n",
    "    [en_klettern_1, en_klettern_2]\n",
    ")\n",
    "print(\"Perplexity for English climbing: \", en_klettern_result.token_perplexity)\n",
    "\n",
    "# English receipe\n",
    "# Prediction: Perplexity should be low.\n",
    "print(\"\\nPrediction: Perplexity should be low.\")\n",
    "en_receipe_result = analyzer.analyze(\n",
    "    [en_receipe_1, en_receipe_2]\n",
    ")\n",
    "print(\"Perplexity for receipe: \", en_receipe_result.token_perplexity)\n",
    "\n",
    "# English unlikely\n",
    "# Predictione: Perplexity should be high.\n",
    "print(\"\\nPrediction: Perplexity should be high.\")\n",
    "en_unlikely_result = analyzer.analyze(\n",
    "    [en_unlikely_1, en_unlikely_2]\n",
    ")\n",
    "print(\"Perplexity for unlikely: \", en_unlikely_result.token_perplexity)\n",
    "\n",
    "# English expert\n",
    "# Prediction: Perplexity should be low.\n",
    "print(\"\\nPrediction: Perplexity should be low.\")\n",
    "en_expert_result = analyzer.analyze(\n",
    "    [en_expert_1, en_expert_2]\n",
    ")\n",
    "print(\"Perplexity for expert: \", en_expert_result.token_perplexity)\n",
    "\n",
    "# English nonsense\n",
    "# Prediction: Perplexity should be high.\n",
    "print(\"\\nPrediction: Perplexity should be high.\")\n",
    "en_nonsense_result = analyzer.analyze(\n",
    "    [en_nonsense_1, en_nonsense_2]\n",
    ")\n",
    "print(\"Perplexity for nonsense: \", en_nonsense_result.token_perplexity)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
